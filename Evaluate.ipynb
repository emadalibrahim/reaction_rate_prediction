{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipynb.fs.full.Utils import arrhenius, plot_results, plot_arrhenius_params, plot_loss, print_error, set_seed\n",
    "from ipynb.fs.full.Model import build_model, model_initialize\n",
    "from ipynb.fs.full.Data_loader import make_data_loader, Scaler, map_to_scale\n",
    "from ipynb.fs.full.Get_fingerprints import get_rdkit_fingerprint, get_cp_fingerprint\n",
    "from sklearn.utils import shuffle\n",
    "from ipynb.fs.full.train_model import train_model\n",
    "from sklearn.model_selection import KFold,StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function takes in a model and test data loader to perform evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model,test_loader,scaler=None):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    features,target,temp= next(iter(test_loader))\n",
    "    features = features.to(device)\n",
    "    temp   = temp.to(device)\n",
    "    model.eval()\n",
    "    try:\n",
    "        model.fck # check if model outputs k\n",
    "        temp = temp.reshape([temp.shape[0],1])\n",
    "        data = torch.cat((features,temp),1)\n",
    "        #data = torch.nan_to_num(data)\n",
    "        logk = model(data)\n",
    "        if model.fck.out_features==1:\n",
    "            target=target[:,0].reshape([target.shape[0],1])\n",
    "        else:\n",
    "            target=target[:,[0,4,8,12]]\n",
    "        if scaler.tscaler != None:\n",
    "            logk = scaler.torch_inverse(logk.to(device))\n",
    "            target = scaler.torch_inverse(target.to(device)).cpu()\n",
    "        kvec=logk.cpu().detach().numpy()\n",
    "        plot_results(target,kvec,temp.cpu())\n",
    "    \n",
    "    except AttributeError :\n",
    "        A,n,B = model(features)\n",
    "        if scaler.tscaler != None:\n",
    "            scaled = scaler.torch_inverse(map_to_scale(A,B,n).to(device))\n",
    "            j = np.array(list(range(model.fcA.out_features)))*3\n",
    "            A = scaled[:,(j+0)]\n",
    "            B = scaled[:,(j+1)]\n",
    "            n = scaled[:,(j+2)]\n",
    "            j = np.array(list(range(model.fcA.out_features)))*4\n",
    "            targetlogk = target[:,j].to(device)\n",
    "            targetA = target[:,(j+1)]\n",
    "            targetB = target[:,(j+2)]\n",
    "            targetn = target[:,(j+3)]\n",
    "            Xt = torch.column_stack([targetA,targetB,targetn]).to(device)\n",
    "            target_scaled = Xt\n",
    "            \n",
    "        logk = torch.ones([A.shape[0],model.fcA.out_features])    \n",
    "        for i in range(model.fcA.out_features):\n",
    "            logk[:,i] = arrhenius(torch.pow(10.,A[:,i].cpu()),n[:,i].cpu(),B[:,i].cpu(),temp.cpu())\n",
    "        kvec=logk.cpu().detach().numpy()\n",
    "        temp = temp.reshape([temp.shape[0],1])\n",
    "        if model.fcA.out_features==1:\n",
    "            target=target[:,0].reshape([target.shape[0],1]).to(device)\n",
    "            #target_scaled=torch.column_stack([target.cpu(),target_scaled.cpu()])\n",
    "        else:\n",
    "            target=target[:,[0,4,8,12]]\n",
    "        plot_results(target.cpu(),kvec,temp.cpu())\n",
    "        #plot_arrhenius_params(target_scaled.cpu(),A.cpu(),n.cpu(),B.cpu())\n",
    "    \n",
    "    print(target.shape,kvec.shape)\n",
    "    RMS = print_error(target.cpu(),kvec)\n",
    "\n",
    "    return(kvec,RMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ABN(model,test_loader,scaler=None):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    features,target,temp= next(iter(test_loader))\n",
    "    features = features.to(device)\n",
    "    temp   = temp.to(device)\n",
    "    model.eval()\n",
    "    try:\n",
    "        model.fck # check if model outputs k\n",
    "        temp = temp.reshape([temp.shape[0],1])\n",
    "        data = torch.cat((features,temp),1)\n",
    "        #data = torch.nan_to_num(data)\n",
    "        logk = model(data)\n",
    "        if model.fck.out_features==1:\n",
    "            target=target[:,0].reshape([target.shape[0],1])\n",
    "        else:\n",
    "            target=target[:,[0,4,8,12]]\n",
    "        if scaler.tscaler != None:\n",
    "            logk = scaler.torch_inverse(logk.to(device))\n",
    "            target = scaler.torch_inverse(target.to(device)).cpu()\n",
    "        kvec=logk.cpu().detach().numpy()\n",
    "        plot_results(target,kvec,temp.cpu())\n",
    "    \n",
    "    except AttributeError :\n",
    "        A,n,B = model(features)\n",
    "        if scaler.tscaler != None:\n",
    "            scaled = scaler.torch_inverse(map_to_scale(A,B,n).to(device))\n",
    "            j = np.array(list(range(model.fcA.out_features)))*3\n",
    "            A = scaled[:,(j+0)]\n",
    "            B = scaled[:,(j+1)]\n",
    "            n = scaled[:,(j+2)]\n",
    "            j = np.array(list(range(model.fcA.out_features)))*4\n",
    "            targetlogk = target[:,j].to(device)\n",
    "            targetA = target[:,(j+1)]\n",
    "            targetB = target[:,(j+2)]\n",
    "            targetn = target[:,(j+3)]\n",
    "            Xt = torch.column_stack([targetA,targetB,targetn]).to(device)\n",
    "            target_scaled = Xt\n",
    "            \n",
    "        logk = torch.ones([A.shape[0],model.fcA.out_features])    \n",
    "        for i in range(model.fcA.out_features):\n",
    "            logk[:,i] = arrhenius(torch.pow(10.,A[:,i].cpu()),n[:,i].cpu(),B[:,i].cpu(),temp.cpu())\n",
    "        kvec=logk.cpu().detach().numpy()\n",
    "        temp = temp.reshape([temp.shape[0],1])\n",
    "        if model.fcA.out_features==1:\n",
    "            target=target[:,0].reshape([target.shape[0],1]).to(device)\n",
    "            #target_scaled=torch.column_stack([target.cpu(),target_scaled.cpu()])\n",
    "        else:\n",
    "            target=target[:,[0,4,8,12]]\n",
    "        plot_results(target.cpu(),kvec,temp.cpu())\n",
    "        #plot_arrhenius_params(target_scaled.cpu(),A.cpu(),n.cpu(),B.cpu())\n",
    "    \n",
    "    print(target.shape,kvec.shape)\n",
    "    RMS = print_error(target.cpu(),kvec)\n",
    "\n",
    "    return(kvec,RMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "Takes in dataframe and parameters to perform K-fold cross-validation on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validate(df,param):\n",
    "    train_molecules = shuffle(df['smiles'].unique())\n",
    "    hebo = df.drop_duplicates(subset=['smiles'])\n",
    "    if param.split == 'Stratified':\n",
    "        kf = StratifiedKFold(n_splits=param.num_folds)\n",
    "    elif param.split == 'Kfold':\n",
    "        kf = KFold(n_splits=param.num_folds)\n",
    "    else:\n",
    "        print('Choose either Stratified or Kfold.')\n",
    "    error = np.zeros((kf.n_splits,4 if param.target == 'All' else 1))\n",
    "    i=0\n",
    "    for train_index, test_index in kf.split(hebo.smiles,hebo.Type):\n",
    "        set_seed(param.seed)\n",
    "        # Split data to train/test folds\n",
    "        print('####### Evaluating fold',i+1,'in a total of',param.num_folds,'folds #######')\n",
    "        train_fold_mols, test_fold_mols = split_data(df,train_molecules[test_index],param)\n",
    "        # Do scaling if needed\n",
    "        Scobj=Scaler()\n",
    "        train_fold_mols,test_fold_mols = Scobj.Scale_data(train_fold_mols,test_fold_mols,param)\n",
    "        # Create and run model\n",
    "        model, criterion, optimizer, scheduler = model_initialize(df,param)\n",
    "        loss = train_model(model,optimizer,criterion,n_epochs=param.n_epochs,weight=param.weights,bweight=param.bweights,\n",
    "                           train_loader=make_data_loader(train_fold_mols,param),\n",
    "                           scheduler=scheduler,valid_loader=make_data_loader(test_fold_mols,param),scaler=Scobj)\n",
    "        plot_loss(loss)\n",
    "        # Evaluate and calculate error\n",
    "        Prediction,error[i,:] = evaluate_model(model,make_data_loader(test_fold_mols,param,test=True),Scobj)\n",
    "        i+=1\n",
    "    print('\\nCV-RMSE=',error.mean(axis=0))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensamble evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ensamble(options_test,param):\n",
    "    df = pd.read_csv('./Data/df.csv')\n",
    "    #make_df()\n",
    "    test_mols  = df.loc[ df['smiles'].isin(options_test)]\n",
    "    target_mols = ['OH','O3','NO3','Cl','All']\n",
    "    target_names= ['oh_logK','o3_logK','no3_logK','cl_logK','logK']\n",
    "    mol = target_names[target_mols.index(param.target)]\n",
    "    Prediction= np.zeros(( test_mols.shape[0] if param.target == 'All' else test_mols.dropna(subset=[mol]).shape[0],\n",
    "                          4 if param.target == 'All' else 1,5))\n",
    "    for i in range(1):\n",
    "        set_seed(param.seed+i*10)\n",
    "        print('####### Evaluating model',i+1,'in an ensamble of 5 #######')\n",
    "        # Load ensamble features\n",
    "        df = pd.read_csv('./Data/df.csv')\n",
    "        df = df.join(get_rdkit_fingerprint(df))\n",
    "        cp_input = pd.read_csv('./Data/VOCensamble{}.csv'.format(i))\n",
    "        cp_features = cp_input.iloc[:,cp_input.columns != 'smiles']\n",
    "        df = df.join(cp_features)\n",
    "        # Split data to train/test sets\n",
    "#         train_mols = shuffle(df.loc[~df['smiles'].isin(options_test)])\n",
    "#         test_mols  = df.loc[ df['smiles'].isin(options_test)]\n",
    "        train_mols, test_mols = split_data(df,options_test,param)\n",
    "        # Do scaling if needed\n",
    "        Scobje=Scaler()\n",
    "        train_mols,test_mols = Scobje.Scale_data(train_mols,test_mols,param)\n",
    "        # Create and run model\n",
    "        model, criterion, optimizer, scheduler = model_initialize(df,param)\n",
    "        loss = train_model(model,optimizer,criterion,n_epochs=param.n_epochs,weight=param.weights,bweight=param.bweights,\n",
    "                           train_loader=make_data_loader(train_mols,param),\n",
    "                           scheduler=scheduler,valid_loader=make_data_loader(test_mols,param),scaler=Scobje) \n",
    "        plot_loss(loss)\n",
    "        test_loader = make_data_loader(test_mols,param,test=True)         \n",
    "        Prediction[:,:,i],_ = evaluate_model(model,test_loader,Scobje)\n",
    "    return Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(df,test_options,param):\n",
    "    # split data\n",
    "    if param.teston == 'All':\n",
    "        train_mols = shuffle(df.loc[~df['smiles'].isin(test_options)])\n",
    "    elif param.teston == 'OH':\n",
    "        train_mols = shuffle(df.copy())\n",
    "        train_mols.loc[df['smiles'].isin(test_options),['oh_logK','oh_A','oh_B','oh_n']] = np.nan\n",
    "    elif param.teston == 'O3':\n",
    "        train_mols = shuffle(df.copy())\n",
    "        train_mols.loc[df['smiles'].isin(test_options),['o3_logK','o3_A','o3_B','o3_n']] = np.nan\n",
    "    elif param.teston == 'NO3':\n",
    "        train_mols = shuffle(df.copy())\n",
    "        train_mols.loc[df['smiles'].isin(test_options),['no3_logK','no3_A','no3_B','no3_n']] = np.nan\n",
    "    elif param.teston == 'Cl':\n",
    "        train_mols = shuffle(df.copy())\n",
    "        train_mols.loc[df['smiles'].isin(test_options),['cl_logK','cl_A','cl_B','cl_n']] = np.nan\n",
    "    else:\n",
    "        print('Target not supported. Please choose from [All,OH,O3,NO3,Cl]')\n",
    "    test_mols  = df.loc[df['smiles'].isin(test_options)]\n",
    "    # trim data\n",
    "    if param.target == 'OH':\n",
    "        label = ['oh_logK']\n",
    "    elif param.target == 'O3':\n",
    "        label = ['o3_logK']\n",
    "    elif param.target == 'NO3':\n",
    "        label = ['no3_logK']\n",
    "    elif param.target == 'Cl':\n",
    "        label = ['cl_logK']\n",
    "    else:\n",
    "        label = ['oh_logK','o3_logK','no3_logK','cl_logK']\n",
    "    train_mols = train_mols.dropna(subset=label,how='all')\n",
    "    test_mols  = test_mols.dropna(subset=label,how='all')\n",
    "\n",
    "    return (train_mols, test_mols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemprop",
   "language": "python",
   "name": "chemprop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
