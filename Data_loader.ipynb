{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loader\n",
    "Creates a data loader given a dataframe and batchsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_data_loader(df,param,test=False):\n",
    "    \n",
    "    if (param.target=='All'):\n",
    "        targets = torch.Tensor(np.array(df[['oh_logK','oh_A','oh_B','oh_n','o3_logK','o3_A','o3_B','o3_n',\n",
    "                                               'no3_logK','no3_A','no3_B','no3_n','cl_logK','cl_A','cl_B','cl_n']]))\n",
    "    elif param.target == 'OH':\n",
    "        df = df.dropna(subset=['oh_logK'])\n",
    "        targets = torch.Tensor(np.array(df[['oh_logK','oh_A','oh_B','oh_n']]))\n",
    "    elif param.target == 'O3':\n",
    "        df = df.dropna(subset=['o3_logK'])\n",
    "        targets = torch.Tensor(np.array(df[['o3_logK','o3_A','o3_B','o3_n']]))\n",
    "    elif param.target == 'NO3':\n",
    "        df = df.dropna(subset=['no3_logK'])\n",
    "        targets = torch.Tensor(np.array(df[['no3_logK','no3_A','no3_B','no3_n']]))\n",
    "    elif param.target == 'Cl':\n",
    "        df = df.dropna(subset=['cl_logK'])\n",
    "        targets = torch.Tensor(np.array(df[['cl_logK','cl_A','cl_B','cl_n']]))\n",
    "    else:\n",
    "        print('Target not supported. Please choose from [All,OH,O3,NO3,Cl]')\n",
    "\n",
    "    if param.input_type == 'Morgan':\n",
    "        df_features = torch.Tensor(np.array(df.iloc[:,df.columns.get_loc(0):df.columns.get_loc(2047)],dtype=float))\n",
    "        features = torch.column_stack([df_features])\n",
    "    elif param.input_type == 'Chemprop':\n",
    "        df_features_cp = torch.Tensor(np.array(df.iloc[:,df.columns.get_loc(\"fp_0\"):],dtype=float))\n",
    "        features = torch.column_stack([df_features_cp])\n",
    "    else:\n",
    "        df_features = torch.Tensor(np.array(df.iloc[:,df.columns.get_loc(0):df.columns.get_loc(2047)],dtype=float))\n",
    "        df_features_cp = torch.Tensor(np.array(df.iloc[:,df.columns.get_loc(\"fp_0\"):],dtype=float))\n",
    "        features = torch.column_stack([df_features,df_features_cp])\n",
    "    \n",
    "    temps = torch.Tensor(np.array(df['T']))\n",
    "    dataset = torch.utils.data.TensorDataset(features,targets,temps)\n",
    "    if test:\n",
    "        loader = torch.utils.data.DataLoader(dataset,batch_size=df.shape[0])\n",
    "    else:\n",
    "        loader = torch.utils.data.DataLoader(dataset,batch_size=param.batch_size)\n",
    "\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Scaler:\n",
    "    \n",
    "    def Scale_data(self,train_mols,test_mols,param):\n",
    "        train_scaled=copy.deepcopy(train_mols)\n",
    "        test_scaled =copy.deepcopy(test_mols)\n",
    "        self.tscaler=None\n",
    "        # Feature scaling\n",
    "        if (param.scale_features == True):\n",
    "            scaler = MinMaxScaler()\n",
    "            if (param.model_type == 'Arrhenius'):\n",
    "                labels = (train_mols.columns.str.startswith('fp_',na=False) | np.array([isinstance(i,int) for i in train_mols]))\n",
    "            elif (param.model_type == 'Point'):\n",
    "                labels = (train_mols.columns.str.startswith('fp_',na=False) | np.array([isinstance(i,int) for i in train_mols]) | (train_mols.columns == 'T') )\n",
    "            train_scaled.loc[:,labels] = scaler.fit_transform(train_mols.loc[:,labels])\n",
    "            test_scaled.loc[:,labels]  = scaler.transform(test_mols.loc[:,labels])\n",
    "        # Target scaling\n",
    "        if (param.scale_targets == True):\n",
    "            self.tscaler = StandardScaler()\n",
    "            if (param.model_type == 'Arrhenius'):\n",
    "                if param.target == 'All':\n",
    "                    tlabels= ((train_mols.columns == 'oh_A')|(train_mols.columns == 'oh_n')|(train_mols.columns == 'oh_B')|\n",
    "                              (train_mols.columns == 'o3_A')|(train_mols.columns == 'o3_n')|(train_mols.columns == 'o3_B')|\n",
    "                              (train_mols.columns == 'no3_A')|(train_mols.columns == 'no3_n')|(train_mols.columns == 'no3_B')|\n",
    "                              (train_mols.columns == 'cl_A')|(train_mols.columns == 'cl_n')|(train_mols.columns == 'cl_B'))\n",
    "                elif param.target == 'OH':\n",
    "                    tlabels= ((train_mols.columns == 'oh_A')|(train_mols.columns == 'oh_n')|(train_mols.columns == 'oh_B'))\n",
    "                elif param.target == 'O3':\n",
    "                    tlabels= ((train_mols.columns == 'o3_A')|(train_mols.columns == 'o3_n')|(train_mols.columns == 'o3_B'))\n",
    "                elif param.target == 'NO3':\n",
    "                    tlabels= ((train_mols.columns == 'no3_A')|(train_mols.columns == 'no3_n')|(train_mols.columns == 'no3_B'))\n",
    "                elif param.target == 'Cl':\n",
    "                    tlabels= ((train_mols.columns == 'cl_A')|(train_mols.columns == 'cl_n')|(train_mols.columns == 'cl_B'))\n",
    "                else:\n",
    "                    print('Target not supported. Please choose from [All,OH,O3,NO3,Cl]')\n",
    "#                 if param.scale_k==True:\n",
    "#                     self.t2scaler = StandardScaler()\n",
    "#                     t2labels= ((train_mols.columns == 'oh_logK')|(train_mols.columns == 'o3_logK')|(train_mols.columns == 'no3_logK')|(train_mols.columns == 'cl_logK'))\n",
    "#                     train_scaled.loc[:,t2labels] = self.t2scaler.fit_transform(train_mols.loc[:,t2labels])\n",
    "#                     test_scaled.loc[:,t2labels]  = self.t2scaler.transform(test_mols.loc[:,t2labels])\n",
    "            elif (param.model_type == 'Point'):\n",
    "                if param.target == 'All':\n",
    "                    tlabels= ((train_mols.columns == 'oh_logK')|(train_mols.columns == 'o3_logK')|(train_mols.columns == 'no3_logK')|(train_mols.columns == 'cl_logK'))\n",
    "                elif param.target == 'OH':\n",
    "                    tlabels= (train_mols.columns == 'oh_logK')\n",
    "                elif param.target == 'O3':\n",
    "                    tlabels= (train_mols.columns == 'o3_logK')\n",
    "                elif param.target == 'NO3':\n",
    "                    tlabels= (train_mols.columns == 'no3_logK')\n",
    "                elif param.target == 'Cl':\n",
    "                    tlabels= (train_mols.columns == 'cl_logK')\n",
    "                else:\n",
    "                    print('Target not supported. Please choose from [All,OH,O3,NO3,Cl]')\n",
    "            train_scaled.loc[:,tlabels] = self.tscaler.fit_transform(train_mols.loc[:,tlabels])\n",
    "            test_scaled.loc[:,tlabels]  = self.tscaler.transform(test_mols.loc[:,tlabels])\n",
    "        return train_scaled,test_scaled\n",
    "    \n",
    "    def torch_inverse(self,X):\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        return((X*torch.Tensor(np.sqrt(self.tscaler.var_)).to(device))+torch.Tensor(self.tscaler.mean_).to(device))\n",
    "    \n",
    "#     def torch_inverse2(self,i,X):\n",
    "#         device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#         return((X*torch.Tensor(np.sqrt(self.t2scaler.var_))[i].to(device))+torch.Tensor(self.t2scaler.mean_)[i].to(device))\n",
    "    \n",
    "#     def torch_transform(self,i,X):\n",
    "#         device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#         return((X-torch.Tensor(self.t2scaler.mean_)[i].to(device))/torch.Tensor(np.sqrt(self.t2scaler.var_))[i].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_to_scale(A,B,n):\n",
    "    if A.shape[1] == 1:\n",
    "        output = torch.column_stack((A,B,n))\n",
    "    else:\n",
    "        output = torch.column_stack([A.reshape([A.shape[0]*A.shape[1]]),B.reshape([B.shape[0]*B.shape[1]]),\n",
    "                                     n.reshape([n.shape[0]*n.shape[1]])]).reshape([A.shape[0],12])\n",
    "    return (output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemprop",
   "language": "python",
   "name": "chemprop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
